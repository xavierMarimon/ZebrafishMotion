{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c102570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge86sof2/.local/lib/python3.8/site-packages/statsmodels/compat/pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge86sof2/miniconda3/envs/DeepLabCut/lib/python3.8/site-packages/deeplabcut/__init__.py:78: UserWarning: \n",
      "        As PyTorch is not installed, unsupervised identity learning will not be available.\n",
      "        Please run `pip install torch`, or ignore this warning.\n",
      "        \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe781d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKIP IF ALREADY CREATED\n",
    "deeplabcut.create_new_project('ZebrafishNet2.0','EduardoSaman', ['/home/ge86sof2/','/home/ge86sof2/'], working_directory='/home/ge86sof2', copy_videos=\n",
    "True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bb783d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERIFY\n",
    "config_path = ('/home/ge86sof2/ZebrafishNet2.0-PortuguesLab-2022-04-28/config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2049e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKIP IF DONE\n",
    "deeplabcut.extract_frames(config_path,'automatic','kmeans',crop=False, userfeedback=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea10805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#START TRAINING FROM HERE\n",
    "deeplabcut.create_training_dataset(config_path, num_shuffles=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368c32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.train_network(config_path,shuffle=1,gputouse=1, displayiters=10,saveiters=5000,maxiters=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7abac64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_resnet50_ZebrafishNet2.0Apr28shuffle1_25000  with # of training iterations: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  outputs = layer.apply(inputs, training=is_training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:12, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis is done and the results are stored (see evaluation-results) for snapshot:  snapshot-25000\n",
      "Results for 25000  training iterations: 95 1 train error: 3.19 pixels. Test error: 3.5  pixels.\n",
      "With pcutoff of 0.6  train error: 3.19 pixels. Test error: 3.5 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "Plotting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:24<00:00,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "Please check the results, then choose the best model (snapshot) for prediction. You can update the config.yaml file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise, consider adding more labeled-data and retraining the network (see DeepLabCut workflow Fig 2, Nath 2019)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(config_path, plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "840a0977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-25000 for model /home/ge86sof2/ZebrafishNet2.0-PortuguesLab-2022-04-28/dlc-models/iteration-0/ZebrafishNet2.0Apr28-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  outputs = layer.apply(inputs, training=is_training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /home/ge86sof2/RESULTS/f5/f5v1/df5s3_v1.mp4\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v1/df5s3_v1.mp4\n",
      "Duration of video [s]:  30.0 , recorded with  113.43 fps!\n",
      "Overall # of frames:  3403  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3400/3403 [00:42<00:00, 79.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/ge86sof2/RESULTS/f5/f5v1...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model /home/ge86sof2/RESULTS/f5/f5v1/df5s3_v1.mp4\n",
      "Saving filtered csv poses!\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v1/df5s3_v1.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "Starting to process video: /home/ge86sof2/RESULTS/f5/f5v1/df5s3_v1.mp4\n",
      "Loading /home/ge86sof2/RESULTS/f5/f5v1/df5s3_v1.mp4 and data.\n",
      "Duration of video [s]: 30.0, recorded with 113.43 fps!\n",
      "Overall # of frames: 3403 with cropped frame dimensions: 480 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3403/3403 [00:10<00:00, 314.95it/s]\n"
     ]
    }
   ],
   "source": [
    "new_vid = ['/home/ge86sof2/RESULTS/f5/f5v1/df5s3_v1.mp4']\n",
    "deeplabcut.analyze_videos(config_path, new_vid, videotype='.mp4', shuffle =1, save_as_csv=True)\n",
    "\n",
    "deeplabcut.filterpredictions(config_path, new_vid, videotype='.mp4', shuffle=1)\n",
    "\n",
    "deeplabcut.plot_trajectories(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n",
    "\n",
    "deeplabcut.create_labeled_video(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e695f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames(config_path, new_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd3f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9809d64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-25000 for model /home/ge86sof2/ZebrafishNet2.0-PortuguesLab-2022-04-28/dlc-models/iteration-0/ZebrafishNet2.0Apr28-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  outputs = layer.apply(inputs, training=is_training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /home/ge86sof2/RESULTS/f5/f5v2/df5s3_v2.mp4\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v2/df5s3_v2.mp4\n",
      "Duration of video [s]:  30.0 , recorded with  121.5 fps!\n",
      "Overall # of frames:  3645  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3636/3645 [00:56<00:00, 64.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/ge86sof2/RESULTS/f5/f5v2...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model /home/ge86sof2/RESULTS/f5/f5v2/df5s3_v2.mp4\n",
      "Saving filtered csv poses!\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v2/df5s3_v2.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "Starting to process video: /home/ge86sof2/RESULTS/f5/f5v2/df5s3_v2.mp4\n",
      "Loading /home/ge86sof2/RESULTS/f5/f5v2/df5s3_v2.mp4 and data.\n",
      "Duration of video [s]: 30.0, recorded with 121.5 fps!\n",
      "Overall # of frames: 3645 with cropped frame dimensions: 480 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3645/3645 [00:09<00:00, 371.21it/s]\n"
     ]
    }
   ],
   "source": [
    "new_vid = ['/home/ge86sof2/RESULTS/f5/f5v2/df5s3_v2.mp4']\n",
    "deeplabcut.analyze_videos(config_path, new_vid, videotype='.mp4', shuffle =1, save_as_csv=True)\n",
    "\n",
    "deeplabcut.filterpredictions(config_path, new_vid, videotype='.mp4', shuffle=1)\n",
    "\n",
    "deeplabcut.plot_trajectories(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n",
    "\n",
    "deeplabcut.create_labeled_video(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3cd58b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-25000 for model /home/ge86sof2/ZebrafishNet2.0-PortuguesLab-2022-04-28/dlc-models/iteration-0/ZebrafishNet2.0Apr28-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  outputs = layer.apply(inputs, training=is_training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /home/ge86sof2/RESULTS/f5/f5v3/df5s3_v3.mp4\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v3/df5s3_v3.mp4\n",
      "Duration of video [s]:  30.01 , recorded with  115.77 fps!\n",
      "Overall # of frames:  3474  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3468/3474 [00:54<00:00, 63.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/ge86sof2/RESULTS/f5/f5v3...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model /home/ge86sof2/RESULTS/f5/f5v3/df5s3_v3.mp4\n",
      "Saving filtered csv poses!\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v3/df5s3_v3.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "Starting to process video: /home/ge86sof2/RESULTS/f5/f5v3/df5s3_v3.mp4\n",
      "Loading /home/ge86sof2/RESULTS/f5/f5v3/df5s3_v3.mp4 and data.\n",
      "Duration of video [s]: 30.01, recorded with 115.77 fps!\n",
      "Overall # of frames: 3474 with cropped frame dimensions: 480 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3474/3474 [00:11<00:00, 314.63it/s]\n"
     ]
    }
   ],
   "source": [
    "new_vid = ['/home/ge86sof2/RESULTS/f5/f5v3/df5s3_v3.mp4']\n",
    "deeplabcut.analyze_videos(config_path, new_vid, videotype='.mp4', shuffle =1, save_as_csv=True)\n",
    "\n",
    "deeplabcut.filterpredictions(config_path, new_vid, videotype='.mp4', shuffle=1)\n",
    "\n",
    "deeplabcut.plot_trajectories(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n",
    "\n",
    "deeplabcut.create_labeled_video(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e98e0c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-25000 for model /home/ge86sof2/ZebrafishNet2.0-PortuguesLab-2022-04-28/dlc-models/iteration-0/ZebrafishNet2.0Apr28-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  outputs = layer.apply(inputs, training=is_training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /home/ge86sof2/RESULTS/f5/f5v4/df5s3_v4.mp4\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v4/df5s3_v4.mp4\n",
      "Duration of video [s]:  30.0 , recorded with  115.43 fps!\n",
      "Overall # of frames:  3463  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 3434/3463 [00:51<00:00, 66.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/ge86sof2/RESULTS/f5/f5v4...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model /home/ge86sof2/RESULTS/f5/f5v4/df5s3_v4.mp4\n",
      "Saving filtered csv poses!\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v4/df5s3_v4.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "Starting to process video: /home/ge86sof2/RESULTS/f5/f5v4/df5s3_v4.mp4\n",
      "Loading /home/ge86sof2/RESULTS/f5/f5v4/df5s3_v4.mp4 and data.\n",
      "Duration of video [s]: 30.0, recorded with 115.43 fps!\n",
      "Overall # of frames: 3463 with cropped frame dimensions: 480 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3463/3463 [00:13<00:00, 249.70it/s]\n"
     ]
    }
   ],
   "source": [
    "new_vid = ['/home/ge86sof2/RESULTS/f5/f5v4/df5s3_v4.mp4']\n",
    "deeplabcut.analyze_videos(config_path, new_vid, videotype='.mp4', shuffle =1, save_as_csv=True)\n",
    "\n",
    "deeplabcut.filterpredictions(config_path, new_vid, videotype='.mp4', shuffle=1)\n",
    "\n",
    "deeplabcut.plot_trajectories(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n",
    "\n",
    "deeplabcut.create_labeled_video(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63535582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-25000 for model /home/ge86sof2/ZebrafishNet2.0-PortuguesLab-2022-04-28/dlc-models/iteration-0/ZebrafishNet2.0Apr28-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  outputs = layer.apply(inputs, training=is_training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /home/ge86sof2/RESULTS/f5/f5v5/df5s3_v5.mp4\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v5/df5s3_v5.mp4\n",
      "Duration of video [s]:  30.01 , recorded with  115.27 fps!\n",
      "Overall # of frames:  3459  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 3434/3459 [00:51<00:00, 66.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/ge86sof2/RESULTS/f5/f5v5...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model /home/ge86sof2/RESULTS/f5/f5v5/df5s3_v5.mp4\n",
      "Saving filtered csv poses!\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v5/df5s3_v5.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "Starting to process video: /home/ge86sof2/RESULTS/f5/f5v5/df5s3_v5.mp4\n",
      "Loading /home/ge86sof2/RESULTS/f5/f5v5/df5s3_v5.mp4 and data.\n",
      "Duration of video [s]: 30.01, recorded with 115.27 fps!\n",
      "Overall # of frames: 3459 with cropped frame dimensions: 480 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3459/3459 [00:10<00:00, 329.23it/s]\n"
     ]
    }
   ],
   "source": [
    "new_vid = ['/home/ge86sof2/RESULTS/f5/f5v5/df5s3_v5.mp4']\n",
    "deeplabcut.analyze_videos(config_path, new_vid, videotype='.mp4', shuffle =1, save_as_csv=True)\n",
    "\n",
    "deeplabcut.filterpredictions(config_path, new_vid, videotype='.mp4', shuffle=1)\n",
    "\n",
    "deeplabcut.plot_trajectories(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n",
    "\n",
    "deeplabcut.create_labeled_video(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f76c709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-25000 for model /home/ge86sof2/ZebrafishNet2.0-PortuguesLab-2022-04-28/dlc-models/iteration-0/ZebrafishNet2.0Apr28-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  outputs = layer.apply(inputs, training=is_training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /home/ge86sof2/RESULTS/f5/f5v6/df5s3_v6.mp4\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v6/df5s3_v6.mp4\n",
      "Duration of video [s]:  30.0 , recorded with  120.0 fps!\n",
      "Overall # of frames:  3600  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3600/3600 [00:51<00:00, 69.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/ge86sof2/RESULTS/f5/f5v6...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model /home/ge86sof2/RESULTS/f5/f5v6/df5s3_v6.mp4\n",
      "Saving filtered csv poses!\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v6/df5s3_v6.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "Starting to process video: /home/ge86sof2/RESULTS/f5/f5v6/df5s3_v6.mp4\n",
      "Loading /home/ge86sof2/RESULTS/f5/f5v6/df5s3_v6.mp4 and data.\n",
      "Duration of video [s]: 30.0, recorded with 120.0 fps!\n",
      "Overall # of frames: 3600 with cropped frame dimensions: 480 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3600/3600 [00:09<00:00, 371.39it/s]\n"
     ]
    }
   ],
   "source": [
    "new_vid = ['/home/ge86sof2/RESULTS/f5/f5v6/df5s3_v6.mp4']\n",
    "deeplabcut.analyze_videos(config_path, new_vid, videotype='.mp4', shuffle =1, save_as_csv=True)\n",
    "\n",
    "deeplabcut.filterpredictions(config_path, new_vid, videotype='.mp4', shuffle=1)\n",
    "\n",
    "deeplabcut.plot_trajectories(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n",
    "\n",
    "deeplabcut.create_labeled_video(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10384e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-25000 for model /home/ge86sof2/ZebrafishNet2.0-PortuguesLab-2022-04-28/dlc-models/iteration-0/ZebrafishNet2.0Apr28-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  outputs = layer.apply(inputs, training=is_training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /home/ge86sof2/RESULTS/f5/f5v7/df5s3_v7.mp4\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v7/df5s3_v7.mp4\n",
      "Duration of video [s]:  30.0 , recorded with  111.7 fps!\n",
      "Overall # of frames:  3351  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 3333/3351 [00:53<00:00, 62.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/ge86sof2/RESULTS/f5/f5v7...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model /home/ge86sof2/RESULTS/f5/f5v7/df5s3_v7.mp4\n",
      "Saving filtered csv poses!\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v7/df5s3_v7.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "Starting to process video: /home/ge86sof2/RESULTS/f5/f5v7/df5s3_v7.mp4\n",
      "Loading /home/ge86sof2/RESULTS/f5/f5v7/df5s3_v7.mp4 and data.\n",
      "Duration of video [s]: 30.0, recorded with 111.7 fps!\n",
      "Overall # of frames: 3351 with cropped frame dimensions: 480 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3351/3351 [00:12<00:00, 268.49it/s]\n"
     ]
    }
   ],
   "source": [
    "new_vid = ['/home/ge86sof2/RESULTS/f5/f5v7/df5s3_v7.mp4']\n",
    "deeplabcut.analyze_videos(config_path, new_vid, videotype='.mp4', shuffle =1, save_as_csv=True)\n",
    "\n",
    "deeplabcut.filterpredictions(config_path, new_vid, videotype='.mp4', shuffle=1)\n",
    "\n",
    "deeplabcut.plot_trajectories(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n",
    "\n",
    "deeplabcut.create_labeled_video(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b27df198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-25000 for model /home/ge86sof2/ZebrafishNet2.0-PortuguesLab-2022-04-28/dlc-models/iteration-0/ZebrafishNet2.0Apr28-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  outputs = layer.apply(inputs, training=is_training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /home/ge86sof2/RESULTS/f5/f5v8/df5s3_v8.mp4\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v8/df5s3_v8.mp4\n",
      "Duration of video [s]:  30.0 , recorded with  122.6 fps!\n",
      "Overall # of frames:  3678  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3672/3678 [00:55<00:00, 66.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/ge86sof2/RESULTS/f5/f5v8...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model /home/ge86sof2/RESULTS/f5/f5v8/df5s3_v8.mp4\n",
      "Saving filtered csv poses!\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v8/df5s3_v8.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "Starting to process video: /home/ge86sof2/RESULTS/f5/f5v8/df5s3_v8.mp4\n",
      "Loading /home/ge86sof2/RESULTS/f5/f5v8/df5s3_v8.mp4 and data.\n",
      "Duration of video [s]: 30.0, recorded with 122.6 fps!\n",
      "Overall # of frames: 3678 with cropped frame dimensions: 480 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3678/3678 [00:14<00:00, 255.70it/s]\n"
     ]
    }
   ],
   "source": [
    "new_vid = ['/home/ge86sof2/RESULTS/f5/f5v8/df5s3_v8.mp4']\n",
    "deeplabcut.analyze_videos(config_path, new_vid, videotype='.mp4', shuffle =1, save_as_csv=True)\n",
    "\n",
    "deeplabcut.filterpredictions(config_path, new_vid, videotype='.mp4', shuffle=1)\n",
    "\n",
    "deeplabcut.plot_trajectories(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n",
    "\n",
    "deeplabcut.create_labeled_video(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b20fa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-25000 for model /home/ge86sof2/ZebrafishNet2.0-PortuguesLab-2022-04-28/dlc-models/iteration-0/ZebrafishNet2.0Apr28-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  outputs = layer.apply(inputs, training=is_training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /home/ge86sof2/RESULTS/f5/f5v9/df5s3_v9.mp4\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v9/df5s3_v9.mp4\n",
      "Duration of video [s]:  30.0 , recorded with  120.1 fps!\n",
      "Overall # of frames:  3603  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3600/3603 [00:56<00:00, 63.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/ge86sof2/RESULTS/f5/f5v9...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model /home/ge86sof2/RESULTS/f5/f5v9/df5s3_v9.mp4\n",
      "Saving filtered csv poses!\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v9/df5s3_v9.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "Starting to process video: /home/ge86sof2/RESULTS/f5/f5v9/df5s3_v9.mp4\n",
      "Loading /home/ge86sof2/RESULTS/f5/f5v9/df5s3_v9.mp4 and data.\n",
      "Duration of video [s]: 30.0, recorded with 120.1 fps!\n",
      "Overall # of frames: 3603 with cropped frame dimensions: 480 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3603/3603 [00:12<00:00, 297.40it/s]\n"
     ]
    }
   ],
   "source": [
    "new_vid = ['/home/ge86sof2/RESULTS/f5/f5v9/df5s3_v9.mp4']\n",
    "deeplabcut.analyze_videos(config_path, new_vid, videotype='.mp4', shuffle =1, save_as_csv=True)\n",
    "\n",
    "deeplabcut.filterpredictions(config_path, new_vid, videotype='.mp4', shuffle=1)\n",
    "\n",
    "deeplabcut.plot_trajectories(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n",
    "\n",
    "deeplabcut.create_labeled_video(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5168c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-25000 for model /home/ge86sof2/ZebrafishNet2.0-PortuguesLab-2022-04-28/dlc-models/iteration-0/ZebrafishNet2.0Apr28-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  outputs = layer.apply(inputs, training=is_training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /home/ge86sof2/RESULTS/f5/f5v10/df5s3_v10.mp4\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v10/df5s3_v10.mp4\n",
      "Duration of video [s]:  30.0 , recorded with  121.8 fps!\n",
      "Overall # of frames:  3654  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3636/3654 [00:54<00:00, 66.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/ge86sof2/RESULTS/f5/f5v10...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model /home/ge86sof2/RESULTS/f5/f5v10/df5s3_v10.mp4\n",
      "Saving filtered csv poses!\n",
      "Loading  /home/ge86sof2/RESULTS/f5/f5v10/df5s3_v10.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "Starting to process video: /home/ge86sof2/RESULTS/f5/f5v10/df5s3_v10.mp4\n",
      "Loading /home/ge86sof2/RESULTS/f5/f5v10/df5s3_v10.mp4 and data.\n",
      "Duration of video [s]: 30.0, recorded with 121.8 fps!\n",
      "Overall # of frames: 3654 with cropped frame dimensions: 480 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3654/3654 [00:12<00:00, 301.34it/s]\n"
     ]
    }
   ],
   "source": [
    "new_vid = ['/home/ge86sof2/RESULTS/f5/f5v10/df5s3_v10.mp4']\n",
    "deeplabcut.analyze_videos(config_path, new_vid, videotype='.mp4', shuffle =1, save_as_csv=True)\n",
    "\n",
    "deeplabcut.filterpredictions(config_path, new_vid, videotype='.mp4', shuffle=1)\n",
    "\n",
    "deeplabcut.plot_trajectories(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n",
    "\n",
    "deeplabcut.create_labeled_video(config_path, new_vid, videotype='.mp4', shuffle=1, filtered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0393fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b805657f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-25000 for model /home/ge86sof2/ZebrafishNet2.0-PortuguesLab-2022-04-28/dlc-models/iteration-0/ZebrafishNet2.0Apr28-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/ge86sof2/.local/lib/python3.8/site-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  outputs = layer.apply(inputs, training=is_training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /home/ge86sof2/RESULTS/f2v10/df2s3_v10.mp4\n",
      "Loading  /home/ge86sof2/RESULTS/f2v10/df2s3_v10.mp4\n",
      "Duration of video [s]:  30.0 , recorded with  120.03 fps!\n",
      "Overall # of frames:  3601  found with (before cropping) frame dimensions:  480 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3600/3601 [01:09<00:00, 51.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/ge86sof2/RESULTS/f2v10...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model /home/ge86sof2/RESULTS/f2v10/df2s3_v10.mp4\n",
      "Saving filtered csv poses!\n",
      "Loading  /home/ge86sof2/RESULTS/f2v10/df2s3_v10.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "Starting to process video: /home/ge86sof2/RESULTS/f2v10/df2s3_v10.mp4\n",
      "Loading /home/ge86sof2/RESULTS/f2v10/df2s3_v10.mp4 and data.\n",
      "Duration of video [s]: 30.0, recorded with 120.03 fps!\n",
      "Overall # of frames: 3601 with cropped frame dimensions: 480 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3601/3601 [00:11<00:00, 300.47it/s]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7c029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLC5",
   "language": "python",
   "name": "dlc5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
